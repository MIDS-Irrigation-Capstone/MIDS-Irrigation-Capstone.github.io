<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>About | SimCLR-S2</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Motivation and SimCLR Background"><meta name=generator content="Hugo 0.81.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css><link rel=stylesheet href=/css/main.css><link href=/about/index.xml rel=alternate type=application/rss+xml title=SimCLR-S2><link href=/about/index.xml rel=feed type=application/rss+xml title=SimCLR-S2><meta property="og:title" content="About"><meta property="og:description" content="Motivation and SimCLR Background"><meta property="og:type" content="website"><meta property="og:url" content="https://mids-irrigation-capstone.github.io/about/"><meta itemprop=name content="About"><meta itemprop=description content="Motivation and SimCLR Background"><meta name=twitter:card content="summary"><meta name=twitter:title content="About"><meta name=twitter:description content="Motivation and SimCLR Background"></head><body class="ma0 avenir bg-near-white"><header class="cover bg-top" style=background-image:url(https://mids-irrigation-capstone.github.io/images/about.jpg)><div class="pb3-m pb6-l bg-black-60"><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">SimCLR-S2</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/data/ title="Data page">Data</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/models/ title="Models page">Models</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/results/ title="Results page">Results</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/team/ title="Team page">Team</a></li></ul><a href=https://github.com/MIDS-Irrigation-Capstone/Spring2021 target=_blank class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel=noopener aria-label="follow on Github——Opens in a new window"><svg height="32" style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></span></a></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><h1 class="f2 f1-l fw2 white-90 mb0 lh-title">About</h1><h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">Motivation and SimCLR Background</h2></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">ABOUT</aside><h1 class="f1 athelas mt3 mb1">About</h1></header><div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-90"><ul><li><a href=#purpose>Purpose</a></li><li><a href=#contrastive-learning>Contrastive Learning</a></li><li><a href=#simclr-framework>SimCLR Framework</a><ul><li><a href=#unsupervised-pretraining>Unsupervised Pretraining</a></li><li><a href=#supervised-fine-tuning>Supervised Fine-Tuning</a></li><li><a href=#distillation>Distillation</a></li></ul></li><li><a href=#why-simclr-s2>Why SimCLR-S2</a></li></ul><h2 id=purpose>Purpose</h2><p>As the global population grows so too does agricultural demand. This increase in demand must be monitored carefully since agricultural production relies on the ability to deliver water to croplands. In the case for California, more than nine million acres of farmland, representing roughly 80% of all water used for businesses and homes. Being able to accurately measure our current and anticipated water needs is critical to ensure that water resources are allocated appropriately to meet basic needs.</p><p>Historically, monitoring water usage has been a largely manual process which is slow and expensive. As technology has evolved we now see ourselves in a situation where we can leverage satellite imagery and computer vision techniques to classify areas of land that are associated with agriculture and irrigation infrastructure. While automation has certainly increased the velocity at which irrigation patterns can be monitored, it still has a highly manual aspect which is a need for labeled data. The aim of this project is to leverage new capabilities in the computer vision space to classify the presence of irrigation in satellite images with a minimal amount of labeled data.</p><h2 id=contrastive-learning>Contrastive Learning</h2><p>The core methodology of our training will leverage contrastive learning to generate a self-supervised model. While typical machine learning models leverage labeled data to identify features that are associated with a label, contrastive learning aims to identify similarities. The basic approach used to train a computer vision model is to apply augmentations to an image and apply a loss function that will minimize the distance between images of the positive class and maximize the distance of all other images.</p><p>The basic process is to apply random augmentations such as crop, blur, rotation, etc. to a batch of N images which results in a training data set of 2N images. Each image in the training set has a corresponding augmented image and the pair is referred to as the &ldquo;positive&rdquo; class. All other images in the training corpus are part of the &ldquo;negative&rdquo; class. This process is outlined in <em>Figure 1</em>.</p><figure><img src=/images/simclr-batch-data-preparation.png alt="Figure 1: SimCLR batch data preparation"><figcaption><p><strong>Figure 1:</strong> <em>SimCLR batch data preparation</em></p></figcaption></figure><p>As the contrastive model learns it will attempt to &ldquo;attract&rdquo; the positive class and &ldquo;repel&rdquo; the negative class to ultimately generate a model that maximizes distance between positive and negative classes. The loss function is based on cosine similarity and is described by the following equation.</p><p><code>$$l_{i,j} = -{log} \frac{exp(sim(z_i,z_j)/\tau)}{\sum_{k=1}^{2N}1_{k \ne i} exp(sim(z_i,z_j)/\tau))}$$</code></p><p>The animation in <em>Figure 2</em> illustrates, at a high, the steps performed during contrastive learning.</p><ol><li>Start with a batch of unlabeled images</li><li>Randomly transform each image</li><li>Pass images through CNN encoder</li><li>Pass encoded images through MLP projection head</li><li>Compute loss</li></ol><figure class="center w-75"><img src=/images/contrastive-learning.gif alt="Figure 2: Contrastive learning methodology"><figcaption><p><strong>Figure 2:</strong> <em>Contrastive learning methodology</em></p></figcaption></figure><h2 id=simclrv2-framework>SimCLRv2 Framework</h2><p>Contrastive learning is just one piece of the puzzle needed to complete the task of labeling irrigated land. The result of training with contrastive learning yields a model that can detect similarity in an image but it cannot classify that image. This is where the SimCLR approach comes into play. There are two versions of SimCLR and version 2 is the current state of the art so will be the version used to build the irrigation classification model.</p><p>At a high-level the SimCLR can be broken down into three steps: unsupervised pretraining, supervised fine-tuning, and distillation. The training pipeling is shown in <em>Figure 3</em>.</p><figure><img src=/images/simCLRv2.png alt="Figure 3: SimCLR version 2 process"><figcaption><p><strong>Figure 3:</strong> <em>SimCLR version 2 process</em></p></figcaption></figure><h3 id=unsupervised-pretraining>Unsupervised Pretraining</h3><p>Unsupervised pretraining leverages the contrasstive learning approach described previously. In this phase a corpus of images is obtained and a model is generated to identify similarities of images. The pretraining is most effective when performed on a large CNN architecture such as ResNet-152. The key here is that all training is done on an entirely unlabeled dataset.</p><h3 id=supervised-fine-tuning>Supervised Fine-Tuning</h3><p>This phase is where the classification model is trained. Using the unsupervised model as a starting point, a fraction of labeled data is used to turn a model that can identify similarities of an image into one that is capable of classifying an image. In order to do this labeled data is required. The important takeaway with this approach is that leveraging the self-supervised model as a starting point should yield a model that has comparable accuracy of a supervised model with a fraction of the labeled data.</p><h3 id=distillation>Distillation</h3><p>The goal of the distillation phase is to shrink the model size while maintaining similar performance. As stated above the unsupervised model performs best when trained on a large model with many parameters. The ideal state is to achieve the best performance with the smallest model. In order to train a smaller model a student/teacher methodology is used.</p><figure class="center w-75"><img src=/images/distillation.png alt="Figure 4: SimCLR student/teacher knowledge distillation"><figcaption><p><strong>Figure 4:</strong> <em>SimCLR student/teacher knowledge distillation</em></p></figcaption></figure><p>Using the fine-tuned model as a teacher we are able to train a much smaller model on unlabeled data by using the teacher to label an image and learning the classification with the smaller model. The goal is to maximize the agreement between the student and the teacher. An important note here is that since the teacher model is labeling data, over-fitting the student model is not a concern.</p><h2 id=why-simclr-s2>Why SimCLR-S2</h2><p>The dataset being used to classify irrigated land in this project is derived from Sentinel-2 satellite imagery. These images are much different from a typical image since there are 12 channels as opposed to the typical 3 RGB channels we are used to. Since SimCLR research was performed on image net with typical RGB images we thought it fitting to name our experiment SimCLR-S2 to determine if the SimCLR technique has the same kind of success with the Sentinel-2 image format.</p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script></body></html>