<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Baseline Models | SimCLR-S2</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Classifying Irrigated Land with Supervised Models"><meta name=generator content="Hugo 0.81.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css><link rel=stylesheet href=/css/main.css><meta property="og:title" content="Baseline Models"><meta property="og:description" content="Classifying Irrigated Land with Supervised Models"><meta property="og:type" content="article"><meta property="og:url" content="https://mids-irrigation-capstone.github.io/models/supervised_baseline/"><meta property="article:section" content="models"><meta itemprop=name content="Baseline Models"><meta itemprop=description content="Classifying Irrigated Land with Supervised Models"><meta itemprop=wordCount content="933"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Baseline Models"><meta name=twitter:description content="Classifying Irrigated Land with Supervised Models"></head><body class="ma0 avenir bg-near-white"><header class="cover bg-top" style=background-image:url(https://mids-irrigation-capstone.github.io/images/migration-baseline-measures.jpg)><div class="pb3-m pb6-l bg-black-60"><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">SimCLR-S2</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/data/ title="Data page">Data</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/models/ title="Models page">Models</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/results/ title="Results page">Results</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/team/ title="Team page">Team</a></li></ul><a href=https://github.com/MIDS-Irrigation-Capstone/Spring2021 target=_blank class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel=noopener aria-label="follow on Github——Opens in a new window"><svg height="32" style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></span></a></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Baseline Models</h1><h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">Classifying Irrigated Land with Supervised Models</h2></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">MODELS</aside><h1 class="f1 athelas mt3 mb1">Baseline Models</h1><div class="pa3 toc nested-links w-90"><p class="f5 b mb3">Contents</p><nav id=TableOfContents><ul><li><a href=#overview>Overview</a></li><li><a href=#full-training>Full training</a><ul><li><a href=#regular-labels>Regular Labels</a></li><li><a href=#expanded-labels>Expanded Labels</a></li></ul></li><li><a href=#imagenet-pretraining>ImageNet Pretraining</a><ul><li><a href=#regular-labels-1>Regular Labels</a></li><li><a href=#expanded-labels-1>Expanded Labels</a></li></ul></li></ul></nav></div></header><div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-90"><h2 id=overview>Overview</h2><p>This project aims to identify if self-supervised learning is a viable option when training on satellite imagery with limited access to labeled data. Our baseline models are trained on various neural network architectures and fractions of labeled data to quantify the performance impact as our fraction of labeled data changes. We will use the baseline models' results to assess the performance of our self-supervised models with the same labeling constraints.</p><p>Before diving into the models, it is essential to understand the methodology for applying the &ldquo;irrigated&rdquo; label. Using the Big Earth Net labels, we identified two different methods to determine irrigation state. We will refer to these methods as regular labels or expanded labels (described below) in our experiments.</p><ul><li><strong>Regular Labels:</strong> Regular labels take the &ldquo;permanently irrigated&rdquo; label from Big Earth Net data and use it as the ground truth for classification. All images that do not include this label are part of the negative class.</li><li><strong>Expanded Labels:</strong> When analyzing the Big Earth Net labels, some of them corresponded to croplands that would imply irrigation. We used these additional labels to broaden what the definition of irrigated is to include the following: Fruit trees and berry plantations, rice fields, vineyards, olive groves, and permanently irrigated.</li></ul><p>In addition to the different labeling methods, we also trained the models in two ways; full training or ImageNet pre-training. The full training experiments train a model from scratch using various fractions of labeled data. The ImageNet pre-training starts off the training with pre-trained weights from an ImageNet model. It is important to note that models trained with ImageNet weights are only trained on RGB channels, while training from scratch utilizes all available channels.</p><p>Baseline models were trained on the following architectures.</p><ul><li>InceptionV3</li><li>ResNet101V2</li><li>ResNet152</li><li>ResNet50</li><li>Xception</li></ul><h2 id=full-training>Full training</h2><p>Models were trained from scratch on each architecture and labeling methodology.</p><h3 id=regular-labels>Regular Labels</h3><p>Supervised model with various splits of labeled data. For the first set of experiments we used only the &ldquo;permanently irrigated&rdquo; label for classification, which is only a small fraction of the dataset at roughly 2.3%. We explore models commonly trained with the ImageNet dataset, and several ResNet models of different sizes, on ever diminishing splits of our labeled dataset.</p><table><caption class="serif f4"><strong>Table 1:</strong> <em>Accuracy versus data splits for full model with regular labels</em></caption><thead><tr><th>Split</th><th style=text-align:center>InceptionV3</th><th style=text-align:center>ResNet101V2</th><th style=text-align:center>ResNet152</th><th style=text-align:center>ResNet50</th><th style=text-align:center>Xception</th></tr></thead><tbody><tr><td>100%</td><td style=text-align:center>0.93925</td><td style=text-align:center>0.93450</td><td style=text-align:center>0.915600</td><td style=text-align:center>0.93275</td><td style=text-align:center><strong>0.93975</strong></td></tr><tr><td>50%</td><td style=text-align:center>0.93550</td><td style=text-align:center>0.90925</td><td style=text-align:center>0.936516</td><td style=text-align:center>0.90650</td><td style=text-align:center><strong>0.93875</strong></td></tr><tr><td>25%</td><td style=text-align:center>0.89875</td><td style=text-align:center>0.92050</td><td style=text-align:center>0.907726</td><td style=text-align:center>0.91900</td><td style=text-align:center><strong>0.92925</strong></td></tr><tr><td>10%</td><td style=text-align:center>0.78500</td><td style=text-align:center><strong>0.89825</strong></td><td style=text-align:center>0.885581</td><td style=text-align:center>0.82050</td><td style=text-align:center>0.89625</td></tr><tr><td>3%</td><td style=text-align:center><strong>0.85025</strong></td><td style=text-align:center>0.83450</td><td style=text-align:center>0.811024</td><td style=text-align:center>0.77100</td><td style=text-align:center>0.65925</td></tr><tr><td>1%</td><td style=text-align:center>0.56800</td><td style=text-align:center>0.52425</td><td style=text-align:center><strong>0.777067</strong></td><td style=text-align:center>0.52225</td><td style=text-align:center>0.49975</td></tr></tbody></table><p>Interestingly, as shown more readily in <em>Figure 1</em> there is a large variance in model performance for ResNet152 and other models. This variance was not consistent and is likely explained by randomness in models with very small data sets. Sometimes the models would perform much better than others which may just be chalked up to luck.</p><figure><img src=/images/supervised_baseline.png alt="Figure 1: Accuracy versus data splits for full model with regular labels"><figcaption><p><strong>Figure 1:</strong> <em>Accuracy versus data splits for full model with regular labels</em></p></figcaption></figure><h3 id=expanded-labels>Expanded Labels</h3><p>Supervised model with various splits of labeled data. In Addition to the &ldquo;permanently irrigated&rdquo; we also include Vineyards, Rice fields, fruit orchards and olive groves, which now represents approximately 6.24% of the dataset.</p><table><caption class="serif f4"><strong>Table 2:</strong> <em>Accuracy versus data splits for full model with expanded labels</em></caption><thead><tr><th>Split</th><th style=text-align:center>InceptionV3</th><th style=text-align:center>ResNet101V2</th><th style=text-align:center>ResNet152</th><th style=text-align:center>ResNet50</th><th style=text-align:center>Xception</th></tr></thead><tbody><tr><td>100%</td><td style=text-align:center><strong>0.888028</strong></td><td style=text-align:center>0.856050</td><td style=text-align:center>NaN</td><td style=text-align:center>0.859056</td><td style=text-align:center>0.885477</td></tr><tr><td>50%</td><td style=text-align:center><strong>0.873269</strong></td><td style=text-align:center>0.819424</td><td style=text-align:center>0.836826</td><td style=text-align:center>0.863794</td><td style=text-align:center>0.847577</td></tr><tr><td>25%</td><td style=text-align:center>0.850856</td><td style=text-align:center>0.837008</td><td style=text-align:center><strong>0.851130</strong></td><td style=text-align:center>0.847303</td><td style=text-align:center>0.840835</td></tr><tr><td>10%</td><td style=text-align:center>0.835550</td><td style=text-align:center><strong>0.847030</strong></td><td style=text-align:center>0.842839</td><td style=text-align:center>0.813138</td><td style=text-align:center>0.844479</td></tr><tr><td>3%</td><td style=text-align:center>0.824071</td><td style=text-align:center>0.817420</td><td style=text-align:center>0.801840</td><td style=text-align:center><strong>0.831906</strong></td><td style=text-align:center>0.830357</td></tr><tr><td>1%</td><td style=text-align:center>0.805029</td><td style=text-align:center><strong>0.808582</strong></td><td style=text-align:center>0.554391</td><td style=text-align:center>0.559311</td><td style=text-align:center>0.627187</td></tr></tbody></table><p>As stated above, it appears that randomness in the training has produced models with a large variance in accuracy for the 1 percent data split. Another interesting observation with using the expanded labels is that model performance improves quickly as opposed the more expected logarithmic curve exhibited when training with regular labels.</p><figure><img src=/images/supervised_baseline_ex.png alt="Figure 2: Accuracy versus data splits for full model with expanded labels"><figcaption><p><strong>Figure 2:</strong> <em>Accuracy versus data splits for full model with expanded labels</em></p></figcaption></figure><h2 id=imagenet-pretraining>ImageNet Pretraining</h2><p>Models were trained on each architecture and labeling methodology using weights from ImageNet as a starting point. When using ImageNet weights the models were only trained on RGB channels.</p><h3 id=regular-labels-1>Regular Labels</h3><p>Supervised model with various splits of labeled data. Used only the &ldquo;permanently irrigated&rdquo; label for classification but trained only on the RGB channels using ImageNet weights.</p><table><caption class="serif f4"><strong>Table 3:</strong> <em>Accuracy versus data splits for pretrained model with regular labels</em></caption><thead><tr><th>Split</th><th style=text-align:center>InceptionV3</th><th style=text-align:center>ResNet101V2</th><th style=text-align:center>ResNet152</th><th style=text-align:center>ResNet50</th><th style=text-align:center>Xception</th></tr></thead><tbody><tr><td>100%</td><td style=text-align:center>0.85600</td><td style=text-align:center>0.88225</td><td style=text-align:center>0.816929</td><td style=text-align:center>0.82875</td><td style=text-align:center><strong>0.89575</strong></td></tr><tr><td>50%</td><td style=text-align:center>0.85425</td><td style=text-align:center>0.88475</td><td style=text-align:center>0.790600</td><td style=text-align:center>0.81050</td><td style=text-align:center><strong>0.88525</strong></td></tr><tr><td>25%</td><td style=text-align:center>0.84125</td><td style=text-align:center>0.85025</td><td style=text-align:center>0.789616</td><td style=text-align:center>0.81700</td><td style=text-align:center><strong>0.87650</strong></td></tr><tr><td>10%</td><td style=text-align:center>0.82425</td><td style=text-align:center>0.73550</td><td style=text-align:center>0.725640</td><td style=text-align:center>0.78925</td><td style=text-align:center><strong>0.83625</strong></td></tr><tr><td>3%</td><td style=text-align:center>0.81675</td><td style=text-align:center>0.84250</td><td style=text-align:center>0.760827</td><td style=text-align:center>0.77600</td><td style=text-align:center><strong>0.84625</strong></td></tr><tr><td>1%</td><td style=text-align:center>0.77875</td><td style=text-align:center>0.78150</td><td style=text-align:center>0.704724</td><td style=text-align:center>0.76625</td><td style=text-align:center><strong>0.82575</strong></td></tr></tbody></table><p>The ImageNet weights seem to produce more consistency in the models across all data splits but does not achieve the same accuracy as the full models as the fraction of labeled data increased. The Xception architecture was the best performing across all data splits.</p><figure><img src=/images/supervised_baseline_pretrained.png alt="Figure 3: Accuracy versus data splits for pretrained model with regular labels"><figcaption><p><strong>Figure 3:</strong> <em>Accuracy versus data splits for pretrained model with regular labels</em></p></figcaption></figure><h3 id=expanded-labels-1>Expanded Labels</h3><p>Supervised model with various splits of labeled data. Used expanded labels (permanently irrigated, Vineyards, Rice fields, fruit orchards and olive groves) for classification but trained only on the RGB channels using ImageNet weights.</p><table><caption class="serif f4"><strong>Table 4:</strong> <em>Accuracy versus data splits for pretrained model with expanded labels</em></caption><thead><tr><th>Split</th><th style=text-align:center>InceptionV3</th><th style=text-align:center>ResNet101V2</th><th style=text-align:center>ResNet152</th><th style=text-align:center>ResNet50</th><th style=text-align:center>Xception</th></tr></thead><tbody><tr><td>100%</td><td style=text-align:center>0.821793</td><td style=text-align:center><strong>0.846028</strong></td><td style=text-align:center>0.792821</td><td style=text-align:center>0.793003</td><td style=text-align:center>0.845117</td></tr><tr><td>50%</td><td style=text-align:center>0.811224</td><td style=text-align:center>0.834001</td><td style=text-align:center>0.784803</td><td style=text-align:center>0.794734</td><td style=text-align:center><strong>0.845208</strong></td></tr><tr><td>25%</td><td style=text-align:center>0.802660</td><td style=text-align:center>0.829173</td><td style=text-align:center>0.775237</td><td style=text-align:center>0.763575</td><td style=text-align:center><strong>0.828626</strong></td></tr><tr><td>10%</td><td style=text-align:center>0.743349</td><td style=text-align:center>0.783710</td><td style=text-align:center>0.754100</td><td style=text-align:center>0.760933</td><td style=text-align:center><strong>0.822522</strong></td></tr><tr><td>3%</td><td style=text-align:center>0.741345</td><td style=text-align:center>0.780703</td><td style=text-align:center>0.752278</td><td style=text-align:center>0.720390</td><td style=text-align:center><strong>0.806214</strong></td></tr><tr><td>1%</td><td style=text-align:center>0.777332</td><td style=text-align:center>0.769133</td><td style=text-align:center>0.737518</td><td style=text-align:center>0.717474</td><td style=text-align:center><strong>0.784074</strong></td></tr></tbody></table><p>The performance with this experiment is very similar to the regular labels with the Xception model appearing to be the best.</p><figure><img src=/images/supervised_baseline_pretrained_ex.png alt="Figure 4: Accuracy versus data splits for pretrained model with expanded labels"><figcaption><p><strong>Figure 4:</strong> <em>Accuracy versus data splits for pretrained model with expanded labels</em></p></figcaption></figure><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script></body></html>