<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>SimCLR-S2 Stage 3: Distillation | SimCLR-S2</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Teacher/Student Knowledge Transfer"><meta name=generator content="Hugo 0.81.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css><link rel=stylesheet href=/css/main.css><meta property="og:title" content="SimCLR-S2 Stage 3: Distillation"><meta property="og:description" content="Teacher/Student Knowledge Transfer"><meta property="og:type" content="article"><meta property="og:url" content="https://mids-irrigation-capstone.github.io/models/simclr_distill/"><meta property="article:section" content="models"><meta property="article:published_time" content="2021-04-06T00:00:00+00:00"><meta property="article:modified_time" content="2021-04-06T00:00:00+00:00"><meta itemprop=name content="SimCLR-S2 Stage 3: Distillation"><meta itemprop=description content="Teacher/Student Knowledge Transfer"><meta itemprop=datePublished content="2021-04-06T00:00:00+00:00"><meta itemprop=dateModified content="2021-04-06T00:00:00+00:00"><meta itemprop=wordCount content="163"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="SimCLR-S2 Stage 3: Distillation"><meta name=twitter:description content="Teacher/Student Knowledge Transfer"></head><body class="ma0 avenir bg-near-white"><header class="cover bg-top" style=background-image:url(https://mids-irrigation-capstone.github.io/images/farmland-simclr.jpg)><div class="pb3-m pb6-l bg-black-60 article-header"><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib site-title">SimCLR-S2</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/about/ title="About page">About</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/data/ title="Data page">Data</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/models/ title="Models page">Models</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/results/ title="Results page">Results</a></li><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/team/ title="Team page">Team</a></li></ul><a href=https://github.com/MIDS-Irrigation-Capstone/Spring2021 target=_blank class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel=noopener aria-label="follow on Github——Opens in a new window"><svg height="32" style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" width="32" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg><span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" width="8" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg></span></a></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><h1 class="f2 f1-l fw2 white-90 mb0 lh-title">SimCLR-S2 Stage 3: Distillation</h1><h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">Teacher/Student Knowledge Transfer</h2></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">MODELS</aside><h1 class="f1 athelas mt3 mb1">SimCLR-S2 Stage 3: Distillation</h1><div class="pa3 toc nested-links w-90"><p class="f5 b mb3">Contents</p><nav id=TableOfContents></nav></div></header><div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-90"><figure><img src=/images/simclr-3.png></figure><p>In this workflow, we use the supervised fine-tuned model from the previous stage as a teacher, in a knowledge distillation process to teach labels for training the unlabeled student network on an architecture of same or smaller size.</p><p>We started with 36 models fine tuned on RestNet152 architecture from stage 2. Each of these models was trained on 5 different convolutional neural networks: Xception, Inception, ResNet50, ResNet101v2 and ResNet152 giving us a total of 180 models.</p><table><caption class="serif f4"><strong>Table 1:</strong> <em>Model parameters for the different CNN architectures we distilled with</em></caption><thead><tr><th style=text-align:center>CNN Architecture</th><th style=text-align:center>Model Parameters (million)</th></tr></thead><tbody><tr><td style=text-align:center>Xcepion</td><td style=text-align:center>22.9</td></tr><tr><td style=text-align:center>InceptionV3</td><td style=text-align:center>23.8</td></tr><tr><td style=text-align:center>ResNet50</td><td style=text-align:center>25.6</td></tr><tr><td style=text-align:center>ResNet101v2</td><td style=text-align:center>44.6</td></tr><tr><td style=text-align:center>ResNet152</td><td style=text-align:center>60.4</td></tr></tbody></table><p>We observed that even the smallest model Xception, with 22.9 million parameters, benefited from distillation with an improved F1 score for data splits from 3% and above. We also observed that distillation scores were better for smaller data sizes on many architectures.</p><figure><img src=/images/distill_1pc_acc.png alt="Figure 1: SimCLR-S2 distillation accuracy on 1% data split"><figcaption><p><strong>Figure 1:</strong> <em>SimCLR-S2 distillation accuracy on 1% data split</em></p></figcaption></figure><figure><img src=/images/distill_10pc_acc.png alt="Figure 1: SimCLR-S2 distillation accuracy on 10% data split"><figcaption><p><strong>Figure 1:</strong> <em>SimCLR-S2 distillation accuracy on 10% data split</em></p></figcaption></figure><ul class=pa0></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"></aside></article></main><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$']],processEscapes:!0,processEnvironments:!0,skipTags:['script','noscript','style','textarea','pre'],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var b=MathJax.Hub.getAllJax(),a;for(a=0;a<b.length;a+=1)b[a].SourceElement().parentNode.className+=' has-jax'}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script></body></html>