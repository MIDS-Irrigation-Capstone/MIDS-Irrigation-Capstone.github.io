---
date: 2021-04-04
title: "SimCLR-S2 Distillation"
description: "Self-Supervised Learning"
featured_image: "/images/farmland-simclr.jpg"
summary_image: "/images/distillation.jpg"
toc: true
summary: In the final set of the SimCLR-S2 process we perform knowledge distillation to attempt to gain similar performance to the big ResNet-152 model with fewer parameters. While it is possible to use some labeled data during distillation we experimented with a completely self-supervised approach.
---


{{< figure src="/images/simclr-3.png" >}}
